{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7399d18-4a20-4c82-9dac-2d4180a7d0ed",
   "metadata": {},
   "source": [
    "# Police Tweets collection\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40107d7-9952-40b3-aada-c02c50bc2505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "import tweepy\n",
    "import configparser\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import time\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e28d3ef-7720-46ad-a876-376e3c49b8d2",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ba69f5-d3eb-4589-b55e-5412a7543491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twitter_data_dir = \"../data/collected_twitter/\"\n",
    "account_info_dir = \"../account_information/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a2058-508f-4e3c-b85c-2433644ae87d",
   "metadata": {},
   "source": [
    "## Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2624af22-2985-4d3a-b1a1-28ba7b7dfcde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser(interpolation=None)\n",
    "config.read(twitter_data_dir + 'keys/config.ini')\n",
    "\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']\n",
    "\n",
    "bearer_token = config['twitter']['bearer_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb756c-5cc3-41ed-9f28-f0387df6daf5",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faced-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to API\n",
    "\n",
    "def authenticate_twitter(api_key, api_key_secret, access_token, access_token_secret):\n",
    "    auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc063d4-7c65-4516-b07c-b01cf547d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = authenticate_twitter(api_key, api_key_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317e613-d8e8-457d-a982-c2b8ea13fc6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Account tweets and search tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09234da1-c9b9-4245-bba5-d3efa8c59090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Handler</th>\n",
       "      <th>Min_id_search</th>\n",
       "      <th>Min_id_account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rīgas pašvaldības policija</td>\n",
       "      <td>@RigasPP</td>\n",
       "      <td>1661733283212988427</td>\n",
       "      <td>1661708433609965568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Préfecture de Police</td>\n",
       "      <td>@prefpolice</td>\n",
       "      <td>1661736653805981698</td>\n",
       "      <td>1661717604870897665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polizei Berlin Einsatz</td>\n",
       "      <td>@PolizeiBerlin_E</td>\n",
       "      <td>1661735417706848257</td>\n",
       "      <td>1661390661407391744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polizei Berlin</td>\n",
       "      <td>@polizeiberlin</td>\n",
       "      <td>1661736926964236292</td>\n",
       "      <td>1661678250903347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>City of London Police</td>\n",
       "      <td>@CityPolice</td>\n",
       "      <td>1661739025554874369</td>\n",
       "      <td>1661728267253211139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Metropolitan Police</td>\n",
       "      <td>@metpoliceuk</td>\n",
       "      <td>1661740733043441671</td>\n",
       "      <td>1661733305535057925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Met Contact Centre</td>\n",
       "      <td>@MetCC</td>\n",
       "      <td>1661750859200622592</td>\n",
       "      <td>1661733890611085318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Police Municipale de Paris</td>\n",
       "      <td>@PMdeParis</td>\n",
       "      <td>1661746030310985728</td>\n",
       "      <td>1661031739181989889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Polizia Roma Capitale</td>\n",
       "      <td>@PLRomaCapitale</td>\n",
       "      <td>1661747097820090373</td>\n",
       "      <td>1432357667528392704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Questura Di Roma</td>\n",
       "      <td>@QuesturaDiRoma</td>\n",
       "      <td>1661623067905253380</td>\n",
       "      <td>1611247422755192835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Policía Municipal de Madrid</td>\n",
       "      <td>@policiademadrid</td>\n",
       "      <td>1661750983804764162</td>\n",
       "      <td>1661714985251385345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Policja Warszawa</td>\n",
       "      <td>@Policja_KSP</td>\n",
       "      <td>1661752032448110599</td>\n",
       "      <td>1661692262298927109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Politie Eenheid Amsterdam</td>\n",
       "      <td>@POL_Amsterdam</td>\n",
       "      <td>1661751938327932930</td>\n",
       "      <td>1661727255406563328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Městská policie Praha</td>\n",
       "      <td>@MP_Praha</td>\n",
       "      <td>1661692161337729025</td>\n",
       "      <td>1632757262824480769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Comando Metropolitano de Lisboa</td>\n",
       "      <td>@psplisboa</td>\n",
       "      <td>1661720683598979079</td>\n",
       "      <td>1661716527643602947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Polisen Stockholm</td>\n",
       "      <td>@polisen_sthlm</td>\n",
       "      <td>1661745590949265413</td>\n",
       "      <td>1661720279536791553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>POLIZEI WIEN</td>\n",
       "      <td>@LPDWien</td>\n",
       "      <td>1661750912912867333</td>\n",
       "      <td>1661688586125598720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kantonspolizei Bern</td>\n",
       "      <td>@PoliceBern</td>\n",
       "      <td>1661735151112704003</td>\n",
       "      <td>1661720737990705158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Københavns Politi</td>\n",
       "      <td>@KobenhavnPoliti</td>\n",
       "      <td>1661744837572575235</td>\n",
       "      <td>1661693982022287360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Helsingin poliisi</td>\n",
       "      <td>@HelsinkiPoliisi</td>\n",
       "      <td>1661751982355533827</td>\n",
       "      <td>1661709479711309824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>OPS Politiet Oslo</td>\n",
       "      <td>@oslopolitiops</td>\n",
       "      <td>1661747300929261578</td>\n",
       "      <td>1661728243727339520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ZG policija feed</td>\n",
       "      <td>@PUzgFeed</td>\n",
       "      <td>1656954287916711936</td>\n",
       "      <td>1604508391803453441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name           Handler        Min_id_search   \n",
       "0        Rīgas pašvaldības policija          @RigasPP  1661733283212988427  \\\n",
       "1              Préfecture de Police       @prefpolice  1661736653805981698   \n",
       "2            Polizei Berlin Einsatz  @PolizeiBerlin_E  1661735417706848257   \n",
       "3                    Polizei Berlin    @polizeiberlin  1661736926964236292   \n",
       "4             City of London Police       @CityPolice  1661739025554874369   \n",
       "5               Metropolitan Police      @metpoliceuk  1661740733043441671   \n",
       "6                Met Contact Centre            @MetCC  1661750859200622592   \n",
       "7        Police Municipale de Paris        @PMdeParis  1661746030310985728   \n",
       "8             Polizia Roma Capitale   @PLRomaCapitale  1661747097820090373   \n",
       "9                  Questura Di Roma   @QuesturaDiRoma  1661623067905253380   \n",
       "10      Policía Municipal de Madrid  @policiademadrid  1661750983804764162   \n",
       "11                 Policja Warszawa      @Policja_KSP  1661752032448110599   \n",
       "12        Politie Eenheid Amsterdam    @POL_Amsterdam  1661751938327932930   \n",
       "13            Městská policie Praha         @MP_Praha  1661692161337729025   \n",
       "14  Comando Metropolitano de Lisboa        @psplisboa  1661720683598979079   \n",
       "15                Polisen Stockholm    @polisen_sthlm  1661745590949265413   \n",
       "16                     POLIZEI WIEN          @LPDWien  1661750912912867333   \n",
       "17              Kantonspolizei Bern       @PoliceBern  1661735151112704003   \n",
       "18                Københavns Politi  @KobenhavnPoliti  1661744837572575235   \n",
       "19                Helsingin poliisi  @HelsinkiPoliisi  1661751982355533827   \n",
       "20                OPS Politiet Oslo    @oslopolitiops  1661747300929261578   \n",
       "21                 ZG policija feed         @PUzgFeed  1656954287916711936   \n",
       "\n",
       "         Min_id_account  \n",
       "0   1661708433609965568  \n",
       "1   1661717604870897665  \n",
       "2   1661390661407391744  \n",
       "3   1661678250903347200  \n",
       "4   1661728267253211139  \n",
       "5   1661733305535057925  \n",
       "6   1661733890611085318  \n",
       "7   1661031739181989889  \n",
       "8   1432357667528392704  \n",
       "9   1611247422755192835  \n",
       "10  1661714985251385345  \n",
       "11  1661692262298927109  \n",
       "12  1661727255406563328  \n",
       "13  1632757262824480769  \n",
       "14  1661716527643602947  \n",
       "15  1661720279536791553  \n",
       "16  1661688586125598720  \n",
       "17  1661720737990705158  \n",
       "18  1661693982022287360  \n",
       "19  1661709479711309824  \n",
       "20  1661728243727339520  \n",
       "21  1604508391803453441  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize min_id = -1 and update it for continuse collecting \n",
    "account_collected_info = account_info_dir+\"name_min_id.csv\"\n",
    "df_min_id = pd.read_csv(account_collected_info)\n",
    "df_min_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e27a85c6-0846-4422-9289-da90dc33c2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RigasPP\n",
      "Retrieved 9 tweets\n",
      "prefpolice\n",
      "Retrieved 8 tweets\n",
      "PolizeiBerlin_E\n",
      "Retrieved 18 tweets\n",
      "polizeiberlin\n",
      "Retrieved 17 tweets\n",
      "CityPolice\n",
      "Retrieved 22 tweets\n",
      "metpoliceuk\n",
      "Retrieved 43 tweets\n",
      "MetCC\n",
      "Retrieved 127 tweets\n",
      "PMdeParis\n",
      "Retrieved 3 tweets\n",
      "PLRomaCapitale\n",
      "QuesturaDiRoma\n",
      "policiademadrid\n",
      "Retrieved 24 tweets\n",
      "Policja_KSP\n",
      "Retrieved 14 tweets\n",
      "POL_Amsterdam\n",
      "Retrieved 8 tweets\n",
      "MP_Praha\n",
      "psplisboa\n",
      "Retrieved 3 tweets\n",
      "polisen_sthlm\n",
      "Retrieved 54 tweets\n",
      "LPDWien\n",
      "Retrieved 62 tweets\n",
      "PoliceBern\n",
      "Retrieved 7 tweets\n",
      "KobenhavnPoliti\n",
      "Retrieved 16 tweets\n",
      "HelsinkiPoliisi\n",
      "Retrieved 13 tweets\n",
      "oslopolitiops\n",
      "Retrieved 61 tweets\n",
      "PUzgFeed\n"
     ]
    }
   ],
   "source": [
    "#recnet 3200 account tweets\n",
    "for i in range(len(df_min_id)):\n",
    "    user = df_min_id.Handler[i][1:]\n",
    "    since_id = df_min_id.Min_id_account[i]\n",
    "    print(user)\n",
    "    #maximum retrive 3200 from one user\n",
    "    tweets = tweepy.Cursor(api.user_timeline,\n",
    "                               screen_name=user,\n",
    "                               since_id = since_id,\n",
    "                               count=200,\n",
    "                               tweet_mode='extended').items(13200)\n",
    "    list_tweets = [tweet._json for tweet in tweets]\n",
    "    \n",
    "    if list_tweets:\n",
    "        most_recent_id = list_tweets[0]['id']\n",
    "        df_min_id.loc[i,'Min_id_account'] = most_recent_id\n",
    "        df_min_id.to_csv(account_collected_info,index=False)\n",
    "\n",
    "\n",
    "        print(\"Retrieved {} tweets\".format(len(list_tweets)))\n",
    "        date = datetime.today().strftime(\"%d-%m-%Y\")\n",
    "        collected_tweets = {\"tweets\":list_tweets}\n",
    "        tweets_storage_file = twitter_data_dir + \"added_account_tweets/collected_\"+ str(len(list_tweets)) + \"_tweets_\" + user + date +\".json\"\n",
    "        with open(tweets_storage_file, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(collected_tweets, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c8aeec-9fc0-4070-bf85-486236f4c623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@RigasPP OR (Rīgas pašvaldības policija)\n",
      "=== saved 220 search on @RigasPP OR (Rīgas pašvaldības policija), with last date 2023-05-20 10:25:29+00:00 and max_id 1661733283212988427 , \n",
      "@prefpolice OR (Préfecture de Police)\n",
      "=== saved 4742 search on @prefpolice OR (Préfecture de Police), with last date 2023-05-20 10:01:38+00:00 and max_id 1661736653805981698 , \n",
      "@PolizeiBerlin_E OR (Polizei Berlin Einsatz)\n",
      "=== saved 4213 search on @PolizeiBerlin_E OR (Polizei Berlin Einsatz), with last date 2023-05-20 10:02:46+00:00 and max_id 1661735417706848257 , \n",
      "@polizeiberlin OR (Polizei Berlin)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== saved 12670 search on @polizeiberlin OR (Polizei Berlin), with last date 2023-05-20 09:57:44+00:00 and max_id 1661736926964236292 , \n",
      "@CityPolice OR (City of London Police)\n",
      "=== saved 1169 search on @CityPolice OR (City of London Police), with last date 2023-05-20 10:17:06+00:00 and max_id 1661739025554874369 , \n",
      "@metpoliceuk OR (Metropolitan Police)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 727\n",
      "Rate limit reached. Sleeping for: 721\n",
      "Rate limit reached. Sleeping for: 732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== saved 50000 search on @metpoliceuk OR (Metropolitan Police), with last date 2023-05-22 09:15:52+00:00 and max_id 1661740733043441671 , \n",
      "@MetCC OR (Met Contact Centre)\n",
      "=== saved 1622 search on @MetCC OR (Met Contact Centre), with last date 2023-05-21 15:17:02+00:00 and max_id 1661750859200622592 , \n",
      "@PMdeParis OR (Police Municipale de Paris)\n",
      "=== saved 305 search on @PMdeParis OR (Police Municipale de Paris), with last date 2023-05-21 15:55:57+00:00 and max_id 1661746030310985728 , \n",
      "@PLRomaCapitale OR (Polizia Roma Capitale)\n",
      "=== saved 175 search on @PLRomaCapitale OR (Polizia Roma Capitale), with last date 2023-05-21 15:13:11+00:00 and max_id 1661747097820090373 , \n",
      "@QuesturaDiRoma OR (Questura Di Roma)\n",
      "=== saved 40 search on @QuesturaDiRoma OR (Questura Di Roma), with last date 2023-05-21 18:04:09+00:00 and max_id 1661623067905253380 , \n",
      "@policiademadrid OR (Policía Municipal de Madrid)\n",
      "=== saved 1878 search on @policiademadrid OR (Policía Municipal de Madrid), with last date 2023-05-21 15:19:10+00:00 and max_id 1661750983804764162 , \n",
      "@Policja_KSP OR (Policja Warszawa)\n",
      "=== saved 180 search on @Policja_KSP OR (Policja Warszawa), with last date 2023-05-21 16:08:42+00:00 and max_id 1661752032448110599 , \n",
      "@POL_Amsterdam OR (Politie Eenheid Amsterdam)\n",
      "=== saved 886 search on @POL_Amsterdam OR (Politie Eenheid Amsterdam), with last date 2023-05-21 15:54:18+00:00 and max_id 1661751938327932930 , \n",
      "@MP_Praha OR (Městská policie Praha)\n",
      "=== saved 24 search on @MP_Praha OR (Městská policie Praha), with last date 2023-05-21 16:18:08+00:00 and max_id 1661692161337729025 , \n",
      "@psplisboa OR (Comando Metropolitano de Lisboa)\n",
      "=== saved 25 search on @psplisboa OR (Comando Metropolitano de Lisboa), with last date 2023-05-21 21:48:10+00:00 and max_id 1661720683598979079 , \n",
      "@polisen_sthlm OR (Polisen Stockholm)\n",
      "=== saved 167 search on @polisen_sthlm OR (Polisen Stockholm), with last date 2023-05-21 15:08:12+00:00 and max_id 1661745590949265413 , \n",
      "@LPDWien OR (POLIZEI WIEN)\n",
      "=== saved 706 search on @LPDWien OR (POLIZEI WIEN), with last date 2023-05-21 15:14:19+00:00 and max_id 1661750912912867333 , \n",
      "@PoliceBern OR (Kantonspolizei Bern)\n",
      "=== saved 41 search on @PoliceBern OR (Kantonspolizei Bern), with last date 2023-05-21 15:39:25+00:00 and max_id 1661735151112704003 , \n",
      "@KobenhavnPoliti OR (Københavns Politi)\n",
      "=== saved 276 search on @KobenhavnPoliti OR (Københavns Politi), with last date 2023-05-21 19:53:27+00:00 and max_id 1661744837572575235 , \n",
      "@HelsinkiPoliisi OR (Helsingin poliisi)\n",
      "=== saved 646 search on @HelsinkiPoliisi OR (Helsingin poliisi), with last date 2023-05-22 09:28:36+00:00 and max_id 1661751982355533827 , \n",
      "@oslopolitiops OR (OPS Politiet Oslo)\n",
      "=== saved 389 search on @oslopolitiops OR (OPS Politiet Oslo), with last date 2023-05-21 15:16:48+00:00 and max_id 1661747300929261578 , \n",
      "@PUzgFeed OR (ZG policija feed)\n"
     ]
    }
   ],
   "source": [
    "# last 10 days search with hander and name\n",
    "# query = [\"Préfecture de Police OR @prefpolice\", \"Rīgas pašvaldības policija OR @RigasPP\"]\n",
    "\n",
    "for i in range(len(df_min_id)):\n",
    "        query = df_min_id.Handler[i]  + \" OR (\"  + df_search.Name[i] + \")\"\n",
    "        # query = df_search.Name[i]\n",
    "        min_id = df_min_id.Min_id_search[i]\n",
    "        print(query)\n",
    "        \n",
    "        tweets = tweepy.Cursor(api.search_tweets,\n",
    "                               q=query,\n",
    "                               count=100,\n",
    "                               since_id = min_id,\n",
    "                               tweet_mode='extended').items(50000)\n",
    "        list_tweets = [tweet._json for tweet in tweets]\n",
    "        \n",
    "        if list_tweets:\n",
    "            most_recent_id = list_tweets[0]['id']\n",
    "            laste_retrived_date = datetime.strptime(list_tweets[-1]['created_at'][4:],'%b %d %H:%M:%S %z %Y')  \n",
    "            \n",
    "            df_min_id.loc[i,'Min_id_search'] = most_recent_id\n",
    "            df_min_id.to_csv(account_collected_info,index=False)\n",
    "            \n",
    "            collected_tweets = {\"tweets\":list_tweets}\n",
    "            tweets_storage_file = twitter_data_dir + \"added_search_tweets/\"+ str(len(list_tweets)) +\"items_\"+ query + \"_\" + str(most_recent_id) + \"_\" + str(laste_retrived_date) + \".json\"\n",
    "            with open(tweets_storage_file, \"w\", encoding='utf-8') as f:\n",
    "                    json.dump(collected_tweets, f, ensure_ascii=False, indent=4)\n",
    "                    print(\"=== saved {} search on {}, with last date {} and max_id {} , \".format(len(list_tweets),query,laste_retrived_date,most_recent_id))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95213407-4e56-4348-a7dd-57e3e4a25e8f",
   "metadata": {},
   "source": [
    "## profile of accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7506f27c-85d6-4bd4-9158-a0efb1672b23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 16:12:22.604 | INFO     | nitter_scraper.nitter:_get_client:31 - Docker connection successful.\n",
      "2023-04-26 16:12:23.926 | INFO     | nitter_scraper.nitter:start:155 - Running container recursing_nobel 597950758c.\n",
      "2023-04-26 16:12:48.385 | INFO     | nitter_scraper.nitter:stop:159 - Stopping container recursing_nobel 597950758c.\n",
      "2023-04-26 16:12:53.566 | INFO     | nitter_scraper.nitter:stop:162 - Container recursing_nobel 597950758c Destroyed.\n"
     ]
    }
   ],
   "source": [
    "#profile info\n",
    "from pprint import pprint\n",
    "\n",
    "from nitter_scraper import NitterScraper\n",
    "list_tweets = []\n",
    "counter = 0\n",
    "\n",
    "with NitterScraper(host=\"0.0.0.0\", port=8008) as nitter:\n",
    "    for username in df.Handler:\n",
    "        profile = nitter.get_profile(username)\n",
    "        list_tweets += [json.loads(profile.json())]\n",
    "        counter += 1\n",
    "\n",
    "    tweets_storage_file = twitter_data_dir + \"profile/profile_\" + str(counter)+\"accounts\" +\".json\"\n",
    "    with open(tweets_storage_file, \"w\", encoding='utf-8') as f:\n",
    "        json.dump(list_tweets, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216073f3-4eec-4827-9379-e0e10eebd9aa",
   "metadata": {},
   "source": [
    "## Filter search tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1384bf-36c8-4f07-b6bc-97ee095290b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_data_dir = twitter_data_dir + \"added_search_tweets/\"\n",
    "all_search_files = [f for f in os.listdir(search_data_dir) if f.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78fe9244-1616-43f2-a118-fc29b0683a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_search(key_word,file_name,df,checkRT):\n",
    "    try:\n",
    "        old_df = pd.read_csv(file_name, low_memory=False)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        old_df = pd.DataFrame()\n",
    "        \n",
    "    if checkRT:\n",
    "        df = df[df.retweeted_status.map(lambda x: all([i in x['full_text'] for i in key_word]))]\n",
    "        \n",
    "    else:\n",
    "        df = df[df.full_text.map(lambda x: all([i in x for i in key_word]))]\n",
    "        \n",
    "    new_df = pd.concat([old_df,df], ignore_index=True)\n",
    "    new_df.drop_duplicates(\"id\").reset_index(drop=True).to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb265605-d20b-4d81-a66e-53991c02c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each search file to check matched @user or account_name string\n",
    "filter_search_dir = \"../data/tweets/filter_search/\"\n",
    "\n",
    "for i in range(len(all_search_files)):\n",
    "    f = all_search_files[i]\n",
    "    \n",
    "    with open(search_data_dir+f) as fp:\n",
    "        data = json.load(fp)['tweets']\n",
    "        df_tweets = pd.DataFrame(data=data)\n",
    "        if len(df_tweets) == 0: continue \n",
    "        \n",
    "        # contian full text\n",
    "        df_tweets = df_tweets[df_tweets.full_text.notna()]\n",
    "        \n",
    "        #  normalise text(accent), Lower case the tweet text\n",
    "        df_tweets.full_text = df_tweets.full_text.map(lambda x: unidecode(x.lower()))\n",
    "        \n",
    "        # remove url\n",
    "        df_tweets.full_text = df_tweets.full_text.map(lambda x: re.sub('http[s]?://\\S+', '', x))\n",
    "        \n",
    "    for i in range(len(df)):\n",
    "        name = df.loc[i,'Name'].lower()\n",
    "        name_en = GoogleTranslator(source='auto', target='en').translate(name)\n",
    "        handler = df.loc[i,'Handler'].lower()\n",
    "        if len(df_tweets) == 0: continue \n",
    "        # check if user is not account itself\n",
    "        df_tweets = df_tweets[df_tweets.user.map(lambda x: x['screen_name'] != handler[1:])]\n",
    "        \n",
    "        \n",
    "        #1.orginial tweets contian: @user | name\n",
    "        if 'retweeted_status' in df_tweets.keys():\n",
    "            df_orig = df_tweets[df_tweets['retweeted_status'].isna() & ~(df_tweets.is_quote_status)]\n",
    "        else: \n",
    "            df_orig = df_tweets[~(df_tweets.is_quote_status)]\n",
    "        if len(df_orig) >0:\n",
    "            checkRT = False\n",
    "            check_search(name.split(),filter_search_dir+\"orginal_\"+name+\".csv\",df_orig,checkRT)\n",
    "            check_search(name_en.split(),filter_search_dir+\"orginal_\"+name+\".csv\",df_orig,checkRT)\n",
    "            check_search([handler],filter_search_dir+\"orginal_\"+handler+\".csv\",df_orig,checkRT)\n",
    "\n",
    "        # 2. quote(reply) contian: @user | name\n",
    "        df_quote = df_tweets[df_tweets.is_quote_status]\n",
    "        if len(df_quote)>0:\n",
    "            checkRT = False\n",
    "            check_search(name.split(),filter_search_dir+\"quote_\"+name+\".csv\",df_quote,checkRT)\n",
    "            check_search(name_en.split(),filter_search_dir+\"quote_\"+name+\".csv\",df_quote,checkRT)\n",
    "            check_search([handler],filter_search_dir+\"quote_\"+handler+\".csv\",df_quote,checkRT)\n",
    "\n",
    "\n",
    "        \n",
    "        #3. retweets from others contian: @user | contain string\n",
    "        if 'retweeted_status' in df_tweets.keys():\n",
    "            df_rt = df_tweets[df_tweets['retweeted_status'].notna()]\n",
    "\n",
    "            df_rt_non_acc = df_rt[df_rt['retweeted_status'].map(lambda x: x['user']['screen_name']!= handler[1:])]\n",
    "            \n",
    "            if len(df_rt_non_acc) > 0:\n",
    "                checkRT = True\n",
    "                check_search(name.split(),filter_search_dir+\"rt_other_rt_\"+name+\".csv\", df_rt_non_acc, checkRT)\n",
    "                check_search(name_en.split(),filter_search_dir+\"rt_other_rt_\"+name+\".csv\", df_rt_non_acc, checkRT)\n",
    "                check_search([handler],filter_search_dir+\"rt_other_rt_\"+handler+\".csv\", df_rt_non_acc, checkRT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b126b-df3c-4aa1-964d-0cca48d6750b",
   "metadata": {},
   "source": [
    "## Merge collected search and account tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7add55-00c3-4e79-83bb-a8a8b24c7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_search_files = [f for f in os.listdir(filter_search_dir) if f.endswith('.csv')]\n",
    "\n",
    "account_data_dir = twitter_data_dir+\"added_account_tweets/\" \n",
    "all_account_files = [f for f in os.listdir(account_data_dir) if f.endswith('.json')]\n",
    "\n",
    "df = pd.read_csv(account_info_dir+'city-label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e5113-2e1c-4091-b64a-3ffc04e06249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign files to each city ccount\n",
    "def assign_files(df,columns_name,all_files):\n",
    "    df[columns_name] = [[] for _ in range(len(df))]\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        handler = df.loc[i,\"Handler\"][1:].lower()\n",
    "        name = df.loc[i,\"Name\"][1:].lower()\n",
    "        files = []\n",
    "        for f in all_files:\n",
    "            if (name in f.lower()) | (handler in f.lower()):\n",
    "                files += [f] \n",
    "        df.at[i,columns_name] = files\n",
    "        \n",
    "    df_city = df.groupby(\"City\")[columns_name].sum().reset_index()\n",
    "    return df_city\n",
    "        \n",
    "df_city_search = assign_files(df,'search_files',filter_search_files)\n",
    "df_city_account = assign_files(df,'account_files',all_account_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a9053-1e5e-4e54-b772-b60f21f709f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_to_city(df_city,tweet_type,to_save_data_dir,open_date_dir,file_column):\n",
    "    for i in range(len(df_city)):\n",
    "        city = df_city.loc[i,'City']\n",
    "        df_collected = pd.DataFrame()\n",
    "\n",
    "        for f in df_city.loc[i,file_column]:\n",
    "            file_path = open_date_dir+f\n",
    "\n",
    "            if f.split('.')[-1] == \"json\":\n",
    "                with open(file_path) as fp:\n",
    "                    data = json.load(fp)[\"tweets\"]\n",
    "                    df_tweets = pd.DataFrame(data=data)\n",
    "                    \n",
    "            elif f.split('.')[-1] == \"csv\":\n",
    "                try:\n",
    "                    df_tweets = pd.read_csv(file_path, low_memory=False)\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    df_tweets = pd.DataFrame()\n",
    "                \n",
    "\n",
    "            df_collected = pd.concat([df_collected,df_tweets], ignore_index=True)\n",
    "\n",
    "        df_collected = df_collected.drop_duplicates(\"id\").reset_index(drop=True)\n",
    "        df_collected.to_csv(to_save_data_dir+city+\"_\"+tweet_type+\"_\"+str(len(df_collected))+\".csv\", index=False)\n",
    "\n",
    "merge_to_city(df_city_search,'search',\"../data/tweets/all_search_city21/\",filter_search_files,'search_files')   \n",
    "merge_to_city(df_city_account,'account',\"../data/tweets/all_account_city/\",account_data_dir,'account_files')     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268435a-d4fc-420d-b186-016f20da8f4c",
   "metadata": {},
   "source": [
    "### Get basic info about each account from colleted profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73adf8d1-be38-4745-bcea-47f7283acc37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_basic_info = pd.read_json(twitter_data_dir + \"profile/profile_21_accounts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ec5df4e-c333-4542-85cc-97cac293ab12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_date = []\n",
    "for i in range(len(df_basic_info)):\n",
    "    account_start_date = api.get_user(screen_name=df_basic_info.username[i])\n",
    "    create_date +=  [account_start_date.created_at]\n",
    "    \n",
    "df_basic_info[\"Created_date\"] = create_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6a2a3af-08fc-4a61-9879-b9ce31b220ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_basic_info.to_csv(account_info_dir+'basic_info.csv',index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
